---
layout: archive
title: SLAM with Kalman Filters
visible: 1
excerpt:
  "SLAM (Simultaneous Localization and Mapping)"
---

SLAM (Simultaneous Localization and Mapping) is the name of the problem where we want to know both the state of the vehicle, for example, the position in a place at the same time as we build a map of the region with the information obtained from the vehicle sensors.

There are different methods. in this post we are going to describe the method using Kalman filters, in particual, the Extended Kalman Filter (EKF) because in general we will have a non-linear system.

# EKF-based Localization

We can start with an easier problem where we are only concerned about the localization, and the map is given as input. In this case, the assumption is that given the information of the sensor, we can detect the landmarks and find that landmark in the map. Then we can use this information to reduce the error of the localization.

The EKF localization algorithm is based on two steps: Prediction and update. The prediction step uses the model dynamics equation to predict the next step, and then we use the observation measurement together with the map to update the state of the vehicle

## Prediction Step
### States Prediction: Robot Motion

The prediction step is perfomed with the robot model, where the current state is predicted with the previous robot state and the measured control input of the robot $u$. The measured control input has noise, so we add a noise model $n$ in the state prediction operation. The noise is modelled as white noise with $\bar{n} = 0$.

$$ \bar{x} \leftarrow f(\bar{x}, u, \bar{n})$$

$$ \bar{x} \leftarrow f(\bar{x}, u, 0)$$

### Updating Robot Covariance

The state covariance is updated with the Jacobian of the process model with respect to the state variables $F_x$.

$$ F_x = \frac{\partial f(\bar{x}, u, 0)}{\partial x}$$

The noise model covariance $Q_u$ is updated with the Jacobian of the process model with respect to the input control $F_u$.

$$ F_u = \frac{\partial f(\bar{x}, u, 0)}{\partial u}$$

The EKF prediction step is then:

$$ \bar{x} \leftarrow f(\bar{x}, u, 0)$$

$$ P \leftarrow F_x PF_x ^T + F_nNF_n^T$$

where the initial covariance matrix P is initially all zeros.

## Updating

### Observation of mapped landmarks

While the robot is moving, it observes the landmarks around it with its sensor. We are going to assume that it has a laser scanner sensor that can predict the position of the landmarks. When the landmarks are detected, we can update the estimated state of the robot with the landmarks measurements and the expected measurements of the landmarks with the measurement model. The error between the real measurement and the expected measurement value is:

$$ \bar{z} = y_i - h(\bar{x}, l_i)$$

where $h(\bar{x}, l_i)$ is the observation measurement model.

With this error measurement, we can update the robot state with the EKF correction step:

$$ \bar{z} = y - h(\bar{x})$$

$$ Z = H_xPH_x^T + R$$

$$K = PH_x^TZ^{-1}$$

$$\bar{x} \leftarrow \bar{x} + K\bar{z} $$

$$P \leftarrow P - KZK^T $$

K is the Kalman gain of the state updating process. The covariance matrix and the state vector is updated based on the Kalman gain value. $H_x$ is the Jacobian of the observation measurement model with respect to the state vector, and R is the noise of the observation measurement model.

## 2D Robot Motion

The state of the robot is:

$$ \bar{x} = \begin{pmatrix}
x \\
y \\
v \\
\theta
\end{pmatrix}$$

where $(x, y)$ is the position, $v$ the velocity, and $\theta$ the heading of the robot, which is the direction of the velocity.

The robot model is given by: 

$$ f(x, u) = \begin{pmatrix}
Vcos\theta \\
Vsin\theta \\
u_v \\
u_{\theta}
\end{pmatrix}$$

where we have two controls $u_v$ and $u_{\theta}$.

We can calculate the Jacobians to find $F_x$ and $F_u$.

$$ F_x(x, u) = \begin{pmatrix}
0 & 0 & cos\theta & -V\sin\theta \\
0 & 0 & sin\theta & V\cos\theta \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
\end{pmatrix}$$

$$ F_u(x, u) = \begin{pmatrix}
0 & 0 \\
0 & 0 \\
1 & 0 \\
0 & 1 \\
\end{pmatrix}$$

The observation measurement model is given by: 

$$ h(x_{l_i}, x) = \begin{pmatrix}
\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} \\
atan(\frac{(y_{l_i} - y)}{(x_{l_i} - x)})
\end{pmatrix}$$

where $x$ is the robot state and $x_{l_i}$ are the landmark measurements. The robot has sensors that can measure the distance and direction of the landmarks.

Then $H_x$ is:

$$ H_x(x_{l_i}, x) = \begin{pmatrix}
-\frac{(x_{l_i} - x)}{\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2}} & -\frac{(y_{l_i} - y)}{\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2}}  \\
 \frac{y_{l_i} - y}{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} & - \frac{x_{l_i} - x}{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} \\
\end{pmatrix}$$

<iframe width="560" height="315"
src="https://www.youtube.com/embed/tLahGJEGwvY" 
frameborder="0" 
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen></iframe>

# EKF-based SLAM

SLAM operation have similar processes as EKF localization, it differes in the initialization of landmarks when detecting new landmarks, to update the robot position.

$$ 
X = 
\begin{bmatrix}
X_x \\
X_l
\end{bmatrix}
 = 
\begin{bmatrix}
X_x \\
L_1 \\
L_2 \\
. \\
. \\
L_n 
\end{bmatrix}
 $$

 $$ P = \begin{bmatrix}
P_{RR} & P_{RL_i} \\
P_{L_i R} & P_{L_i L_i} 
\end{bmatrix}
$$

## Prediction step

### Update Robot State

This part is almost the same:

$$ \bar{x} \leftarrow f(\bar{x}, u, 0)$$

with an additional relation for the landmarks.

$$ \bar{x_l} \leftarrow \bar{x_l}$$

### Update Robot Covariance

$$ P_{RR} \leftarrow F_x P_{RR}F_x ^T + F_nNF_n^T$$

$$ P_{RL_i} \leftarrow F_xP_{RL_i}$$

$$ P_{L_iR} \leftarrow P_{RL_i}^T$$

$$ P_{L_iL_i} \leftarrow P_{L_iL_i}$$

## Update Step

$$ \bar{z} = y_i - h_i(\bar{R}, S, \bar{L_i})$$

 $$ Z = \begin{bmatrix}
H_R & H_{L_i}
\end{bmatrix} \begin{bmatrix}
P_{RR} & P_{RL_i} \\
P_{L_i R} & P_{L_i L_i} 
\end{bmatrix} \begin{bmatrix}
H_R^T \\ H_{L_i}^T
\end{bmatrix} + R$$

 $$ K = \begin{bmatrix}
P_{RR} & P_{RL_i} \\
P_{L_i R} & P_{L_i L_i} 
\end{bmatrix} \begin{bmatrix}
H_R^T \\ H_{L_i}^T
\end{bmatrix}Z^{-1}$$

$$ \bar{x} \leftarrow \bar{x} + K\bar{z}$$

$$ P \leftarrow P - KZK^T$$

### Landmark Initialization

When the robot observes a landmark for the first time, the landmarks have not registered on the map, so we have to estimate the global coordinates based on the measurements of the robot. The estimated state of these landmarks are calculated with the invert of the observation function.

$$ L_i = g(\bar{x}, \bar{y}_i) $$

The Jacobian are:

$$ G_R = \frac{\partial g(\bar{x}, \bar{y}_i)}{\partial x}$$

$$ G_y = \frac{\partial g(\bar{x}, \bar{y}_i)}{\partial y}$$

And the covariance and cross covariance:

$$ P_{L_i L_i} = G_x P_{x x} G_x^T + G_yRG_y^T$$

$$ P_{L_i X} = G_x P_{R x}$$

The new landmarks states and the covariance are:

$$ 
X \leftarrow 
\begin{bmatrix}
X \\
L_{n+1}
\end{bmatrix}
$$

 $$ P = \begin{bmatrix}
P & P_{L_i X}^T \\
P_{L_i X} & P_{L_i L_i} 
\end{bmatrix}
$$

## 2D Robot Motion

We return to the 2D tobot

$$ \bar{x} = \begin{pmatrix}
x \\
y \\
v \\
\theta
\end{pmatrix}$$

where $(x, y)$ is the position, $v$ the velocity, and $\theta$ the heading of the robot, which is the direction of the velocity.

The robot model is given by: 

$$ f(x, u) = \begin{pmatrix}
Vcos\theta \\
Vsin\theta \\
u_v \\
u_{\theta}
\end{pmatrix}$$

where we have two controls $u_v$ and $u_{\theta}$.



The observation measurement model is given by: 

$$ h(x_{l_i}, x) = \begin{pmatrix}
\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} \\
atan(\frac{(y_{l_i} - y)}{(x_{l_i} - x)})
\end{pmatrix}$$

where $x$ is the robot state and $x_{l_i}$ are the landmark measurements. The robot has sensors that can measure the distance and direction of the landmarks.

Then $H_x$ is:

$$ H_x(x_{l_i}, x) = \begin{pmatrix}
-\frac{(x_{l_i} - x)}{\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2}} & -\frac{(y_{l_i} - y)}{\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2}}  \\
 \frac{y_{l_i} - y}{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} & - \frac{x_{l_i} - x}{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} \\
\end{pmatrix}$$

And now we need to calculate also $H_{L_i}$.

$$ H_{L_i}(x_{l_i}, x) = \begin{pmatrix}
\frac{(x_{l_i} - x)}{\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2}} & \frac{(y_{l_i} - y)}{\sqrt{(x_{l_i} - x)^2 + (y_{l_i} - y)^2}}  \\
 -\frac{y_{l_i} - y}{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} &  \frac{x_{l_i} - x}{(x_{l_i} - x)^2 + (y_{l_i} - y)^2} \\
\end{pmatrix}$$

The position of each landmark is given by the measurement of the distance and angle with respect to the robot:

$$ \bar{y}_i = \begin{pmatrix}
r \\
\psi
\end{pmatrix} $$

So g is:

$$ g(\bar{x}, \bar{y}_i) = \begin{pmatrix}
x + rcos(\psi) \\
y + sin(\psi)
\end{pmatrix} $$

and the jacobian are:

$$ G_x = \begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix} $$

$$ G_y = \begin{pmatrix}
cos(\psi) & -rsin(\psi) \\
sin(\psi) & rcos(psi)
\end{pmatrix} $$

<iframe width="560" height="315"
src="https://www.youtube.com/embed/uu-LfTPCSxU" 
frameborder="0" 
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" 
allowfullscreen></iframe>

Code: https://github.com/ajimenezh/EKF-Slam